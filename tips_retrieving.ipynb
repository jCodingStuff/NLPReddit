{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving data for our Tips bot #\n",
    "\n",
    "In this notebook we will retrieve posts for *LifeProTips*, *ShittyLifeProTips*, *UnethicalLifeProTips* and *IllegalLifeProTips*.\n",
    "\n",
    "---\n",
    "\n",
    "To start, we import `praw` and configure the Reddit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from psaw import PushshiftAPI\n",
    "import json\n",
    "\n",
    "reddit = praw.Reddit(client_id='<your client id>',\n",
    "                     client_secret='<your client secret>',\n",
    "                     user_agent='<your user id>',\n",
    "                     username='<your user id>',\n",
    "                     password='<your password>')\n",
    "\n",
    "api = PushshiftAPI(reddit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define retrieval method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(post_dict, tag):\n",
    "    '''Put <tag> as the value for the post_dict key <label>.'''\n",
    "    \n",
    "    post_dict['label'] = tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "def post_retrieval(file, subreddit, date, count=500):\n",
    "    '''Retrieve <count> posts from <subreddit> from <date> onwards and dump them into <file>.'''\n",
    "    \n",
    "    # Create empty post list\n",
    "    posts = []\n",
    "    \n",
    "    submissions = api.search_submissions(after=date, subreddit=subreddit, limit=None, sort=\"date:asc\")\n",
    "    counter = 0\n",
    "    \n",
    "    for submission in submissions:\n",
    "        #Retrieve set variables from the submission object and store them in a post dictionary\n",
    "        post = vars(submission)\n",
    "        post_dict = {field:post[field] for field in post_fields[:-1]} # Don't fill label yet\n",
    "        \n",
    "        label(post_dict, subreddit)\n",
    "        posts.append(post_dict)\n",
    "        \n",
    "        # After 1000 posts are added they're written into the data file, this is done to ensure that the progress\n",
    "        # is not lost in case of internet connection issues or other problems\n",
    "        if len(posts)%1000 == 0:\n",
    "            print(\"We're at: \" + str(len(posts)))\n",
    "            with open(file, 'w+') as f:\n",
    "                json.dump(posts, f)\n",
    "        \n",
    "        # Check if we have arrived to <count>\n",
    "        if counter == count:\n",
    "                return\n",
    "        \n",
    "        # Update counter\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we a list with the names of the subreddits we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = ('lifeprotips', 'shittylifeprotips', 'unethicallifeprotips', 'illegallifeprotips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manage for several retrievals, put an `file_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the desired fields and retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieving 30000 posts from lifeprotips starting by 1514761200\n",
      "We're at: 1000\n",
      "We're at: 2000\n",
      "We're at: 3000\n",
      "We're at: 4000\n",
      "We're at: 5000\n",
      "We're at: 6000\n",
      "We're at: 7000\n",
      "We're at: 8000\n",
      "We're at: 9000\n",
      "We're at: 10000\n",
      "We're at: 11000\n",
      "We're at: 12000\n",
      "We're at: 13000\n",
      "We're at: 14000\n",
      "We're at: 15000\n",
      "We're at: 16000\n",
      "We're at: 17000\n",
      "We're at: 18000\n",
      "We're at: 19000\n",
      "We're at: 20000\n",
      "We're at: 21000\n",
      "We're at: 22000\n",
      "We're at: 23000\n",
      "We're at: 24000\n",
      "We're at: 25000\n",
      "We're at: 26000\n",
      "We're at: 27000\n",
      "We're at: 28000\n",
      "We're at: 29000\n",
      "We're at: 30000\n",
      "\n",
      "Retrieving 30000 posts from shittylifeprotips starting by 1514761200\n",
      "We're at: 1000\n",
      "We're at: 2000\n",
      "We're at: 3000\n",
      "We're at: 4000\n",
      "We're at: 5000\n",
      "We're at: 6000\n",
      "We're at: 7000\n",
      "We're at: 8000\n",
      "We're at: 9000\n",
      "We're at: 10000\n",
      "We're at: 11000\n",
      "We're at: 12000\n",
      "We're at: 13000\n",
      "We're at: 14000\n",
      "We're at: 15000\n",
      "We're at: 16000\n",
      "We're at: 17000\n",
      "We're at: 18000\n",
      "We're at: 19000\n",
      "We're at: 20000\n",
      "We're at: 21000\n",
      "We're at: 22000\n",
      "We're at: 23000\n",
      "We're at: 24000\n",
      "We're at: 25000\n",
      "We're at: 26000\n",
      "We're at: 27000\n",
      "We're at: 28000\n",
      "We're at: 29000\n",
      "We're at: 30000\n",
      "\n",
      "Retrieving 30000 posts from unethicallifeprotips starting by 1514761200\n",
      "We're at: 1000\n",
      "We're at: 2000\n",
      "We're at: 3000\n",
      "We're at: 4000\n",
      "We're at: 5000\n",
      "We're at: 6000\n",
      "We're at: 7000\n",
      "We're at: 8000\n",
      "We're at: 9000\n",
      "We're at: 10000\n",
      "We're at: 11000\n",
      "We're at: 12000\n",
      "We're at: 13000\n",
      "We're at: 14000\n",
      "We're at: 15000\n",
      "We're at: 16000\n",
      "We're at: 17000\n",
      "We're at: 18000\n",
      "We're at: 19000\n",
      "We're at: 20000\n",
      "We're at: 21000\n",
      "We're at: 22000\n",
      "We're at: 23000\n",
      "We're at: 24000\n",
      "We're at: 25000\n",
      "We're at: 26000\n",
      "We're at: 27000\n",
      "We're at: 28000\n",
      "We're at: 29000\n",
      "We're at: 30000\n",
      "\n",
      "Retrieving 30000 posts from illegallifeprotips starting by 1514761200\n",
      "We're at: 1000\n",
      "We're at: 2000\n",
      "We're at: 3000\n",
      "We're at: 4000\n",
      "We're at: 5000\n",
      "We're at: 6000\n",
      "We're at: 7000\n",
      "We're at: 8000\n",
      "We're at: 9000\n",
      "We're at: 10000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Fields to be retrieved from submissions and comments and subreddit from which we will be extracting them\n",
    "#comment_fields = ('id', 'body', 'link_id', 'permalink', 'score', 'subreddit_id')\n",
    "post_fields = ('id','name', 'created_utc', 'title', 'selftext', 'score', 'label')\n",
    "\n",
    "count = 30000\n",
    "\n",
    "# Retrieve for subreddits\n",
    "for subreddit in subreddits:\n",
    "    \n",
    "    # Period from which we want to retrieve the comments\n",
    "    date = int(dt.datetime(2018,1,1).timestamp())\n",
    "    \n",
    "    # Check if there are previous dumps of the subreddit, so that we continue from its last date\n",
    "    old_dump = 'tips/{}_dump_{}.json'.format(subreddit, file_id-1)\n",
    "    if os.path.isfile(old_dump):\n",
    "        with open(old_dump, 'r') as f:\n",
    "            dump_list = json.load(f)\n",
    "            date = int(dump_list[-1]['created_utc'])\n",
    "    \n",
    "    print('\\nRetrieving {} posts from {} starting by {}'.format(count, subreddit, date))\n",
    "    \n",
    "    post_retrieval('tips/{}_dump_{}.json'.format(subreddit, file_id), subreddit, date, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DONE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
